{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! python Chrome-dino.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import ImageGrab\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "game_url = \"game/dino.html\"\n",
    "chrome_driver_path = \"../chromedriver.exe\"\n",
    "class Game:\n",
    "    def __init__(self,custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        self._driver = webdriver.Chrome(executable_path = chrome_driver_path,chrome_options=chrome_options)\n",
    "        self._driver.set_window_position(x=-10,y=0)\n",
    "        self._driver.set_window_size(200, 300)\n",
    "        self._driver.get(os.path.abspath(game_url))\n",
    "        if custom_config:\n",
    "            self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "    def get_crashed(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.playing\")\n",
    "    def restart(self):\n",
    "        return self._driver.execute_script(\"Runner.instance_.restart()\")\n",
    "    def press_up(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_UP)\n",
    "    def press_down(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_DOWN)\n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array)\n",
    "        return int(score)\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DinoAgent:\n",
    "    def __init__(self,game):\n",
    "        self._game = game;\n",
    "        self.jump();\n",
    "    def is_running(self):\n",
    "        return self._game.get_playing()\n",
    "    def is_crashed(self):\n",
    "        return self._game.get_crashed()\n",
    "    def jump(self):\n",
    "        self._game.press_up()\n",
    "    def duck(self):\n",
    "        self._game.press_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#processing image as required\n",
    "def process_img(image):\n",
    "    #image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)qqq\n",
    "    #game is already in grey scale canvas, canny to get only edges and reduce unwanted objects(clouds)\n",
    "    image = cv2.Canny(image, threshold1 = 100, threshold2 = 200)\n",
    "    #image = resized_image = cv2.resize(image, (80, 80)) \n",
    "    image = cv2.resize(image, (0,0), fx = 0.50, fy = 0.50)\n",
    "    #image = cv2.fastNlMeansDenoisingColored(image,None,10,10,7,21)\n",
    "    return  image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_screen():\n",
    "    screen =  np.array(ImageGrab.grab(bbox=(0,180,400,400)))\n",
    "    image = process_img(screen)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grab_screen().shape)\n",
    "# game = Game()\n",
    "# dino = DinoAgent(game)\n",
    "# last_time = time.time()\n",
    "# while(True):\n",
    "    \n",
    "# #     print('loop took {} seconds'.format(time.time()-last_time))\n",
    "# #     last_time = time.time()\n",
    "# #     cv2.imwrite(\"./img_data/dino\"+str(time())+\".jpg\",image)\n",
    "# #     dino.duck()\n",
    "#     #exit on q pres\n",
    "#     image,r_t,end_t = get_state(game,dino,2)\n",
    "# #     print('{0} {1} '.format(r_t,end_t))\n",
    "#     #cv2.imshow('window',image)\n",
    "#     if(dino.is_crashed()):\n",
    "#         #jumping starts the game again if dino has crashed\n",
    "#         print(game.get_score())\n",
    "#         game.restart()\n",
    "        \n",
    "#     if (cv2.waitKey(25) & 0xFF == ord('q')):\n",
    "#         cv2.destroyAllWindows()\n",
    "#         game.end()\n",
    "#         cv2.imwrite('dino.jpg',image)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Game_sate:\n",
    "    def __init__(self,agent,game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._showImg = show_img()\n",
    "        self._showImg.__next__()\n",
    "            \n",
    "    def get_state(self,actions=0):\n",
    "        \n",
    "        reward = 0.1\n",
    "        is_over = False\n",
    "        if actions == 1:\n",
    "            self._agent.jump()\n",
    "            reward = 0.1\n",
    "#         elif (actions[2] == 1):\n",
    "# #             self._agent.duck()\n",
    "#             self._agent.jump()\n",
    "#             reward = 0.1\n",
    "#         if self._agent.is_crashed():\n",
    "#             self._game.restart()\n",
    "#             reward = -1\n",
    "#             is_over = True\n",
    "        image = grab_screen()\n",
    "        self._showImg.send(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_img():\n",
    "    \"\"\"\n",
    "    Coroutine to store images in the \"images\" directory\n",
    "    \"\"\"\n",
    "    frame = 0\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        cv2.imshow(\"preview\", screen)\n",
    "        if (cv2.waitKey(25) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "        frame += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def episode():\n",
    "    \"\"\" \n",
    "    Coroutine of episode. \n",
    "    \n",
    "    Action has to be explicitly send to this coroutine.\n",
    "    \"\"\"\n",
    "    game = Game()\n",
    "    dino = DinoAgent(game)\n",
    "    game_state = Game_sate(dino,game)\n",
    "    while True:\n",
    "        end = int(dino.is_crashed())\n",
    "        if end :\n",
    "            end *= -1\n",
    "            game.restart()\n",
    "            \n",
    "        actions = yield game_state.get_state(), end  \n",
    "        game_state.get_state(actions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import sample as rsample\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experience_replay(batch_size):\n",
    "    \"\"\"\n",
    "    Coroutine function for implementing experience replay.    \n",
    "        Provides a new experience by calling \"send\", which in turn yields \n",
    "        a random batch of previous replay experiences.\n",
    "    \"\"\"\n",
    "    memory = []\n",
    "    while True:\n",
    "        # experience is a tuple containing (S, action, reward, S_prime)\n",
    "        experience = yield rsample(memory, batch_size) if batch_size <= len(memory) else None\n",
    "        memory.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epochs = 1000\n",
    "batch_size = 128\n",
    "epsilon = .8\n",
    "gamma = .8\n",
    "ACTIONS = 2\n",
    "# Recipe of deep reinforcement learning model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32,(3,3), input_shape=(110, 200,1), activation='relu'))\n",
    "model.add(Convolution2D(64,(3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(ACTIONS))\n",
    "model.compile(RMSprop(), 'MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_replay = experience_replay(batch_size)\n",
    "exp_replay.__next__()  # Start experience-replay coroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def play_game():\n",
    "    for i in range(nb_epochs):\n",
    "        ep = episode()\n",
    "        S, won = ep.__next__()  # Start coroutine of single entire episode\n",
    "        loss = 0.\n",
    "        try:\n",
    "            while True:\n",
    "#                 action = np.zeros(ACTIONS)\n",
    "#                 action_index = random.randrange(ACTIONS) \n",
    "#                 action[action_index] = 1\n",
    "                action = 0\n",
    "                if np.random.random() > epsilon:\n",
    "                    # Get the index of the maximum q-value of the model.\n",
    "                    # Subtract one because actions are either -1, 0, or 1\n",
    "                    q = model.predict(S.reshape(1,110,200,1))       \n",
    "                    max_Q = np.argmax(q, axis=-1)\n",
    "                    action_index = max_Q-1\n",
    "#                     action[action_index] = 1\n",
    "                    action = action_index\n",
    "                S_prime, won = ep.send(action)\n",
    "                experience = (S, action, won, S_prime)\n",
    "                S = S_prime\n",
    "\n",
    "                batch = exp_replay.send(experience)\n",
    "                if batch:\n",
    "                    inputs = []\n",
    "                    targets = []\n",
    "                    for s, a, r, s_prime in batch:\n",
    "                        # The targets of unchosen actions are the q-values of the model,\n",
    "                        # so that the corresponding errors are 0. The targets of chosen actions\n",
    "                        # are either the rewards, in case a terminal state has been reached, \n",
    "                        # or future discounted q-values, in case episodes are still running.\n",
    "                        t = model.predict(S.reshape(1,110,200,1)).flatten()\n",
    "                        t[a + 1] = r\n",
    "                        if not r:\n",
    "                            t[a + 1] = r + gamma * model.predict(s_prime.reshape(1,110,200,1)).max(axis=-1)\n",
    "                        targets.append(t)\n",
    "                        inputs.append(s)\n",
    "                        print('training')\n",
    "                    loss += model.train_on_batch(np.array(inputs).reshape(1,110,200,1), np.array(targets))[0]\n",
    "\n",
    "        except StopIteration:\n",
    "            pass\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print ('Epoch %i, loss: %.6f' % (i + 1, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
